# Transformer from "Attention is all you need" for language translation

My own implementation of the Transformer proposed in the paper [Attention Is All You Need](https://arxiv.org/abs/1706.03762). Transformer is a network architecture that is based solely on attention mechanisms without any use of LSTMs or RNNs. I applied the Transformer to translate sentences from Portuguese to English. 
([Jupyter Notebook](https://nbviewer.jupyter.org/github/vgkortsas/Transformer/blob/master/Transformer_language_translation.ipynb))


## Requirements
A full list of the requirements is given [here](https://github.com/vgkortsas/Transformer_language_translation/blob/master/requirements.txt). The Python and deep learning library versions are:
- Python 3.5.5
- TensorFlow 1.15.0


## Reference
[Attention Is All You Need](https://arxiv.org/abs/1706.03762)





