# Transformer model for language translation
My own implementation of the Transformer, a network architecture that is based solely on attention mechanisms without any use of LSTMs or RNNs. I applied the Transformer to translate sentences from Portuguese to English. 

## Project
[Transformer model for language translation](https://github.com/vgkortsas/Transformer_language_translation/blob/master/Transformer_language_translation.ipynb): Implementation of the Transformer, using TensorFlow 1.15.

## Requirements
A full list of the requirements is given [here](https://github.com/vgkortsas/Transformer_language_translation/blob/master/requirements.txt). The Python and deep learning library versions are:
- Python 3.5.5
- TensorFlow 1.15.0


## Reference
[Attention Is All You Need](https://arxiv.org/abs/1706.03762)





