# Transformer model for language translation
My own implementation of the Transformer, a network architecture that is based solely on attention mechanisms, without any use of LSTMs or RNNs

##Reference
[Attention Is All You Need](https://arxiv.org/abs/1706.03762)



[Transformer model for language translation](https://github.com/vgkortsas/Transformer_language_translation/blob/master/Transformer_language_translation.ipynb): Implementation of the Transformer, a network architecture that was proposed in the paper "Attention Is All You Need" and applying it to translate sentences from Portuguese to English. 



